# ğŸ“° AI News Agent  
### LangChain + Ollama + Tavily Search

This project is a local AI-powered news agent built using:

- LangChain
- Ollama (Local LLM)
- Tavily Search API
- Node.js
- TypeScript

The agent fetches real-time news using a search tool and summarizes it into structured bullet points.

---

# ğŸš€ Features

- ğŸ” Live web search integration (Tavily)
- ğŸ§  Local LLM reasoning (Ollama)
- ğŸ“° Summarized news output
- âš¡ Tool-calling AI agent architecture
- ğŸ–¥ Runs completely from terminal

---

# ğŸ›  Tech Stack

- Node.js
- TypeScript
- LangChain
- Ollama
- Tavily API
- dotenv

---

# ğŸ“¦ Prerequisites

Make sure you have:

- **Node.js v18+**
- **Ollama installed**
- **Tavily API Key**

Download Ollama from:

ğŸ‘‰ https://ollama.com/download

---

# âš™ï¸ Installation & Setup

Follow these steps to run the project.

---

## 1ï¸âƒ£ Create Project Folder

```bash
mkdir ai-news-agent
cd ai-news-agent
2ï¸âƒ£ Initialize Node Project
npm init -y
3ï¸âƒ£ Install Dependencies
npm install langchain @langchain/core @langchain/ollama @langchain/tavily dotenv
For TypeScript support:

npm install -D typescript tsx @types/node
4ï¸âƒ£ Install Ollama Model
Pull the required model:

ollama pull qwen3:4b
Verify installation:

ollama list
5ï¸âƒ£ Setup Environment Variables
Create a .env file in the root folder:

TAVILY_API_KEY=your_actual_api_key_here
Replace with your real Tavily API key.

â–¶ï¸ Running the Agent
Start the agent using:

npx tsx index.ts
The agent will:

Search latest news

Use LLM reasoning

Return 5 summarized bullet points

ğŸ’¬ Example Prompt Used
"What is today's latest news in Mumbai? Give summarized answer with 5 bullet points."
You can modify the prompt inside index.ts.

ğŸ“ Project Structure
ai-news-agent/
â”‚
â”œâ”€â”€ index.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ .env
â”œâ”€â”€ node_modules/
â””â”€â”€ README.md





